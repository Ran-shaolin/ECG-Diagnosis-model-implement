{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "from tqdm import tqdm_notebook\n",
    "import json\n",
    "import shutil\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import xlrd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from ECG_Dataset_class import ECG_Dataset\n",
    "from util_wqaq_1D import *\n",
    "from ECG_Quant_Net import ECG_Quant_Net, ECG_Net, quantization_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = json.load(open('config.json', 'r'))\n",
    "\n",
    "train_data = ECG_Dataset(txt = params[\"multilabel_save_folder\"]+'train.txt', transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=params[\"batch_size\"], shuffle=True,num_workers=16,pin_memory=True)\n",
    "val_data = ECG_Dataset(txt= params[\"multilabel_save_folder\"]+'validation.txt', transform=transforms.ToTensor())\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=params[\"batch_size\"], shuffle=False,num_workers=16,pin_memory=True)\n",
    "test_data = ECG_Dataset(txt= params[\"multilabel_save_folder\"]+'test.txt', transform=transforms.ToTensor())\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=params[\"batch_size\"], shuffle=False,num_workers=16,pin_memory=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tmp = {i: len(os.listdir(os.path.join(params[\"ecg_root_path\"], j))) for i, j in enumerate(sorted(\n",
    "    os.listdir(params[\"ecg_root_path\"]), key=lambda x: int(x[0]) if x[1] == '-' else int(x[:2])))}\n",
    "counter = Counter(tmp)\n",
    "max_val = float(max(counter.values()))       \n",
    "class_weight_tmp = {class_id : max_val/num_ecg for class_id, num_ecg in counter.items()}\n",
    "c_weight = []\n",
    "for key,val in class_weight_tmp.items():\n",
    "    c_weight.append(val)\n",
    "class_weight = torch.FloatTensor(c_weight).to(device)\n",
    "Loss_fn = nn.BCELoss(weight = class_weight).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_CKPT = torch.load('./ECG/finetune_slimming_model.pth.tar')\n",
    "model  = ECG_Net(init_weights= False, num_classes=26, cfg = model_CKPT['cfg']).to(device)\n",
    "model.load_state_dict(model_CKPT['state_dict'])\n",
    "model_q = ECG_Quant_Net(init_weights= False, num_classes=26, cfg = model_CKPT['cfg'], act_bits =8, weight_bits = 8, q_type = 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv_module = []\n",
    "model_batchnorm_module = []\n",
    "model_liner_module = []\n",
    "\n",
    "model_q_conv_module  =[]\n",
    "model_q_liner_module= []\n",
    "\n",
    "for m0 in model.modules():\n",
    "    if isinstance(m0, nn.Conv1d):\n",
    "        model_conv_module.append(m0)\n",
    "        \n",
    "        \n",
    "    if isinstance(m0, nn.BatchNorm1d):\n",
    "        model_batchnorm_module.append(m0)\n",
    "    if isinstance(m0, nn.Linear):\n",
    "        model_liner_module.append(m0)  \n",
    "        \n",
    "        \n",
    "for m1 in model_q.modules():\n",
    "    if isinstance(m1, BNFold_Conv1d_Q):\n",
    "        model_q_conv_module.append(m1)\n",
    "    if isinstance(m1, Linear_Q):\n",
    "        model_q_liner_module.append(m1)\n",
    "\n",
    "for [m0, m1] in zip(model_conv_module, model_q_conv_module):\n",
    "    w = m0.weight.data.clone()    \n",
    "    m1.weight.data = w.clone()\n",
    "    m1.bias.data = m0.bias.data.clone()#\n",
    "\n",
    "for [m0, m1] in zip(model_batchnorm_module, model_q_conv_module):      \n",
    "    w = m0.weight.data.clone()    \n",
    "    m1.gamma.data = w.clone()\n",
    "    m1.beta.data = m0.bias.data.clone()       \n",
    "        \n",
    "model_q_liner_module[0].weight.data = model_liner_module[0].weight.data.clone()\n",
    "model_q_liner_module[0].bias.data = model_liner_module[0].bias.data.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 15\n",
    "lr = 1e-5\n",
    "optimizer = torch.optim.Adam(model_q.parameters(),lr = lr, betas = (0.9, 0.999),eps = 1e-8, weight_decay = 0)\n",
    "\n",
    "model_q,avg_train_losses, avg_valid_losses = quantization_train(model_q,train_loader,val_loader,params[\"batch_size\"], num_epochs,Loss_fn,optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
